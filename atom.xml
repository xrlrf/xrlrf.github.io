<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>xiaorui&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wustxiao.cn/"/>
  <updated>2017-10-09T11:31:02.501Z</updated>
  <id>http://wustxiao.cn/</id>
  
  <author>
    <name>Xiao Rui</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python网络爬虫与信息提取(三)：网络爬虫之实战</title>
    <link href="http://wustxiao.cn/2017/10/09/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96-%E4%B8%89-%EF%BC%9A%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B9%8B%E5%AE%9E%E6%88%98/"/>
    <id>http://wustxiao.cn/2017/10/09/Python网络爬虫与信息提取-三-：网络爬虫之实战/</id>
    <published>2017-10-09T11:30:11.000Z</published>
    <updated>2017-10-09T11:31:02.501Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Re(正则表达式)库入门</strong></p><pre><code>regular expression = regex = RE是一种通用的字符串表达框架,用来简洁表达一组字符串的表达式,也可用来判断某字符串的特征归属</code></pre><p><strong>正则表达式的语法</strong><br><img src="http://img.blog.csdn.net/20171003172550881?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>常用操作符</strong><br><img src="http://img.blog.csdn.net/20171003172903007?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>实例</strong><br><img src="http://img.blog.csdn.net/20171003173123271?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20171003173148932?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>Re库的基本使用</strong></p><ul><li>正则表达式的表示类型为raw string类型(原生字符串类型),表示为r’text’</li><li><p>Re库主要功能函数<br><img src="http://img.blog.csdn.net/20171003173600313?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p></li><li><p>功能函数</p></li><li><strong>re.search(pattern,string,flags=0)</strong></li></ul><p><img src="http://img.blog.csdn.net/20171003174502422?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20171003175004492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><ul><li><p><strong>re.match(pattern,string,flags=0)</strong></p><p> 因为match为从开始位置开始匹配,使用时要加if进行判别返回结果是否为空,否则会报错</p></li></ul><p><img src="http://img.blog.csdn.net/20171003174827459?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><ul><li><strong>re.findall(pattern,string,flags=0)</strong><br><img src="http://img.blog.csdn.net/20171003175333187?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></li><li><p><strong>re.split(pattern,string,maxsplit=0,flags=0)</strong></p><pre><code>maxsplit为最大分割数,剩余部分作为最后一个元素输出</code></pre></li></ul><p><img src="http://img.blog.csdn.net/20171003175818527?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><ul><li><strong>re.finditer(pattern,string,flags=0)</strong></li></ul><p><img src="http://img.blog.csdn.net/20171003180036474?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><ul><li><p><strong>re.sub(pattern,repl,string,count=0,flags=0)</strong></p><pre><code>repl是用来替换的字符串,count为替换次数</code></pre></li></ul><p><img src="http://img.blog.csdn.net/20171003180256096?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><ul><li><strong>Re库的另一种等价用法</strong></li></ul><p>Re库的函数式用法为一次性操作,还有一种为面向对象用法,可在编译后多次操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">regex = re.compile(pattern,flags=0)</div></pre></td></tr></table></figure><p><strong>通过compile生成的regex对象才能被叫做正则表达式</strong><br><img src="http://img.blog.csdn.net/20171003180754812?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>Match对象的属性</strong></p><p><img src="http://img.blog.csdn.net/20171003212506588?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>Match对象的方法</strong></p><p><img src="http://img.blog.csdn.net/20171003212601752?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>例子</strong></p><p><img src="http://img.blog.csdn.net/20171003212745305?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><pre><code>Re库的贪婪匹配和最小匹配Re库默认采取贪婪匹配,即输出匹配最长的子串</code></pre><p><img src="http://img.blog.csdn.net/20171003212936289?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>实例二:淘宝商品比价定向爬虫(requests-re)</strong></p><pre><code>步骤1:提交商品搜索请求,循环获取页面步骤2:对于每个页面,提取商品名称和价格信息步骤3:将信息输出显示</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">import requests</div><div class="line">import re</div><div class="line"></div><div class="line">def getHTMLText(url):</div><div class="line">    try:</div><div class="line">        r = requests.get(url, timeout=30)</div><div class="line">        r.raise_for_status()</div><div class="line">        r.encoding = r.apparent_encoding</div><div class="line">        return r.text</div><div class="line">    except:</div><div class="line">        return &quot;&quot;</div><div class="line"></div><div class="line">def parsePage(ilt, html):</div><div class="line">    try:</div><div class="line">        plt = re.findall(r&apos;\&quot;view_price\&quot;\:\&quot;[\d\.]*\&quot;&apos;,html)</div><div class="line">        tlt = re.findall(r&apos;\&quot;raw_title\&quot;\:\&quot;.*?\&quot;&apos;,html)</div><div class="line">        for i in range(len(plt)):</div><div class="line">            price = eval(plt[i].split(&apos;:&apos;)[1])</div><div class="line">            title = eval(tlt[i].split(&apos;:&apos;)[1])</div><div class="line">            ilt.append([price , title])</div><div class="line">    except:</div><div class="line">        print(&quot;&quot;)</div><div class="line"></div><div class="line">def printGoodsList(ilt):</div><div class="line">    tplt = &quot;&#123;:4&#125;\t&#123;:8&#125;\t&#123;:16&#125;&quot;</div><div class="line">    print(tplt.format(&quot;序号&quot;, &quot;价格&quot;, &quot;商品名称&quot;))</div><div class="line">    count = 0</div><div class="line">    for g in ilt:</div><div class="line">        count = count + 1</div><div class="line">        print(tplt.format(count, g[0], g[1]))</div><div class="line"></div><div class="line">def main():</div><div class="line">    goods = &apos;书包&apos;</div><div class="line">    depth = 3</div><div class="line">    start_url = &apos;https://s.taobao.com/search?q=&apos; + goods</div><div class="line">    infoList = []</div><div class="line">    for i in range(depth):</div><div class="line">        try:</div><div class="line">            url = start_url + &apos;&amp;s=&apos; + str(44*i)</div><div class="line">            html = getHTMLText(url)</div><div class="line">            parsePage(infoList, html)</div><div class="line">        except:</div><div class="line">            continue</div><div class="line">    printGoodsList(infoList)</div><div class="line"></div><div class="line">main()</div></pre></td></tr></table></figure><p><strong>实例三:股票数据定向爬虫</strong></p><pre><code>步骤1:从东方财富网获取股票列表步骤2:根据股票列表逐个到百度股票获取个股信息步骤3:将结果存储到文件</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line">#CrawBaiduStocksB.py</div><div class="line">import requests</div><div class="line">from bs4 import BeautifulSoup</div><div class="line">import traceback</div><div class="line">import re</div><div class="line"></div><div class="line">def getHTMLText(url, code=&quot;utf-8&quot;):</div><div class="line">    try:</div><div class="line">        r = requests.get(url)</div><div class="line">        r.raise_for_status()</div><div class="line">        r.encoding = code</div><div class="line">        return r.text</div><div class="line">    except:</div><div class="line">        return &quot;&quot;</div><div class="line"></div><div class="line">def getStockList(lst, stockURL):</div><div class="line">    html = getHTMLText(stockURL, &quot;GB2312&quot;)</div><div class="line">    soup = BeautifulSoup(html, &apos;html.parser&apos;)</div><div class="line">    a = soup.find_all(&apos;a&apos;)</div><div class="line">    for i in a:</div><div class="line">        try:</div><div class="line">            href = i.attrs[&apos;href&apos;]</div><div class="line">            lst.append(re.findall(r&quot;[s][hz]\d&#123;6&#125;&quot;, href)[0])</div><div class="line">        except:</div><div class="line">            continue</div><div class="line"></div><div class="line">def getStockInfo(lst, stockURL, fpath):</div><div class="line">    count = 0</div><div class="line">    for stock in lst:</div><div class="line">        url = stockURL + stock + &quot;.html&quot;</div><div class="line">        html = getHTMLText(url)</div><div class="line">        try:</div><div class="line">            if html==&quot;&quot;:</div><div class="line">                continue</div><div class="line">            infoDict = &#123;&#125;</div><div class="line">            soup = BeautifulSoup(html, &apos;html.parser&apos;)</div><div class="line">            stockInfo = soup.find(&apos;div&apos;,attrs=&#123;&apos;class&apos;:&apos;stock-bets&apos;&#125;)</div><div class="line"></div><div class="line">            name = stockInfo.find_all(attrs=&#123;&apos;class&apos;:&apos;bets-name&apos;&#125;)[0]</div><div class="line">            infoDict.update(&#123;&apos;股票名称&apos;: name.text.split()[0]&#125;)</div><div class="line"></div><div class="line">            keyList = stockInfo.find_all(&apos;dt&apos;)</div><div class="line">            valueList = stockInfo.find_all(&apos;dd&apos;)</div><div class="line">            for i in range(len(keyList)):</div><div class="line">                key = keyList[i].text</div><div class="line">                val = valueList[i].text</div><div class="line">                infoDict[key] = val</div><div class="line"></div><div class="line">            with open(fpath, &apos;a&apos;, encoding=&apos;utf-8&apos;) as f:</div><div class="line">                f.write( str(infoDict) + &apos;\n&apos; )</div><div class="line">                count = count + 1</div><div class="line">                print(&quot;\r当前进度: &#123;:.2f&#125;%&quot;.format(count*100/len(lst)),end=&quot;&quot;)</div><div class="line">        except:</div><div class="line">            count = count + 1</div><div class="line">            print(&quot;\r当前进度: &#123;:.2f&#125;%&quot;.format(count*100/len(lst)),end=&quot;&quot;)</div><div class="line">            continue</div><div class="line"></div><div class="line">def main():</div><div class="line">    stock_list_url = &apos;http://quote.eastmoney.com/stocklist.html&apos;</div><div class="line">    stock_info_url = &apos;https://gupiao.baidu.com/stock/&apos;</div><div class="line">    output_file = &apos;D:/BaiduStockInfo.txt&apos;</div><div class="line">    slist=[]</div><div class="line">    getStockList(slist, stock_list_url)</div><div class="line">    getStockInfo(slist, stock_info_url, output_file)</div><div class="line"></div><div class="line">main()</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Re(正则表达式)库入门&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;regular expression = regex = RE
是一种通用的字符串表达框架,用来简洁表达一组字符串的表达式,也可用来判断某字符串的特征归属
&lt;/code&gt;&lt;/pre&gt;&lt;
      
    
    </summary>
    
      <category term="Python学习" scheme="http://wustxiao.cn/categories/Python%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Python" scheme="http://wustxiao.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python网络爬虫与信息提取(二)：网络爬虫之提取</title>
    <link href="http://wustxiao.cn/2017/10/09/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96-%E4%BA%8C-%EF%BC%9A%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B9%8B%E6%8F%90%E5%8F%96/"/>
    <id>http://wustxiao.cn/2017/10/09/Python网络爬虫与信息提取-二-：网络爬虫之提取/</id>
    <published>2017-10-09T11:28:12.000Z</published>
    <updated>2017-10-09T11:29:23.970Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Beautiful Soup库可对HTML/XML格式进行解析并提取相关信息</strong></p><p>安装:  <code>pip install beautifulsoup4</code></p><p>小测：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; import requests</div><div class="line">&gt;&gt;&gt; r = requests.get(&quot;http://python123.io/ws/demo.html&quot;)</div><div class="line">&gt;&gt;&gt; r.text</div><div class="line">&gt;&gt;&gt; demo = r.text</div><div class="line">&gt;&gt;&gt; from bs4 import BeautifulSoup</div><div class="line">&gt;&gt;&gt; soup = BeautifulSoup(demo,&quot;html.parser&quot;)</div><div class="line">&gt;&gt;&gt; print(soup.prettify())</div></pre></td></tr></table></figure><p><img src="http://img.blog.csdn.net/20171003111747222?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><img src="http://img.blog.csdn.net/20171003111805980?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>Beautiful Soup库是解析/遍历/维护”标签熟”的功能库,引用方式:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">from bs4 import BeautifulSoup</div><div class="line">import bs4</div></pre></td></tr></table></figure><p><strong>Beautiful Soup库的4种解析器:</strong></p><p><img src="http://img.blog.csdn.net/20171003125633014?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>Beautiful Soup类的基本元素:</strong></p><p><img src="http://img.blog.csdn.net/20171003125726046?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>bs类基本元素</strong></p><ul><li><p>Tag标签<br><img src="http://img.blog.csdn.net/20171003130356706?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br>任何存在于HTML语法中的标签都可用**soup.<tag>访问获得,存在多个取第一个</tag></p></li><li><p>Tag的name<br><img src="http://img.blog.csdn.net/20171003130504074?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"><br>每个<tag>有自己的名字,通过<tag>.name获取,字符串类型</tag></tag></p></li><li><p>Tag的attrs<br><img src="http://img.blog.csdn.net/20171003130840431?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p></li><li><p>Tag的NavigableString<br><img src="http://img.blog.csdn.net/20171003131039781?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p></li><li><p>Tag的Comment<br><img src="http://img.blog.csdn.net/20171003131409233?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p></li><li><p>由find_all()扩展的七个方法:<br><img src="http://img.blog.csdn.net/20171003132419274?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p></li></ul><p><strong>实例一:中国大学排名爬虫</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python</div><div class="line"># coding=utf-8</div><div class="line">import requests</div><div class="line">from bs4 import BeautifulSoup</div><div class="line">import bs4</div><div class="line"></div><div class="line">def getHTMLText(url):</div><div class="line">    try:</div><div class="line">        r = requests.get(url,timeout=30)</div><div class="line">        r.raise_for_status()</div><div class="line">        r.encoding=r.apparent_encoding</div><div class="line">        return r.text</div><div class="line">    except:</div><div class="line">        return &quot;error&quot;</div><div class="line"></div><div class="line">def fillUnivList(ulist,html):</div><div class="line">    soup=BeautifulSoup(html,&quot;html.parser&quot;)</div><div class="line">    for tr in soup.find(&apos;tbody&apos;).children:</div><div class="line">        if isinstance(tr,bs4.element.Tag):</div><div class="line">            tds = tr(&apos;td&apos;)</div><div class="line">            ulist.append([tds[0].string,tds[1].string,tds[2].string])</div><div class="line"></div><div class="line">def printUnivList(ulist,num):</div><div class="line">    tplt=&quot;&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;&quot;</div><div class="line">    print(tplt.format(&quot;排名&quot;,&quot;学校名称&quot;,&quot;总分&quot;,chr(12288)))</div><div class="line">    for i in range(num):</div><div class="line">        u=ulist[i]</div><div class="line">        print(tplt.format(u[0],u[1],u[2],chr(12288)))</div><div class="line"></div><div class="line">def main():</div><div class="line">    uinfo=[]</div><div class="line">    url = &quot;http://www.zuihaodaxue.cn/zuihaodaxuepaiming2016.html&quot;</div><div class="line">    html = getHTMLText(url)</div><div class="line">    fillUnivList(uinfo,html)</div><div class="line">    printUnivList(uinfo,20)</div><div class="line">main()</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Beautiful Soup库可对HTML/XML格式进行解析并提取相关信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;安装:  &lt;code&gt;pip install beautifulsoup4&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;小测：&lt;/p&gt;
&lt;figure class=
      
    
    </summary>
    
      <category term="Python学习" scheme="http://wustxiao.cn/categories/Python%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Python" scheme="http://wustxiao.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python网络爬虫与信息提取(一)</title>
    <link href="http://wustxiao.cn/2017/10/09/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96-%E4%B8%80/"/>
    <id>http://wustxiao.cn/2017/10/09/Python网络爬虫与信息提取-一/</id>
    <published>2017-10-09T11:24:30.000Z</published>
    <updated>2017-10-09T11:25:45.988Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Requests库的七个主要方法:</strong></p><p><img src="http://img.blog.csdn.net/20171003091430199?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>get方法</strong></p><pre><code>r = requests.get(url):右边构造一个向服务器请求资源的Requests对象,左边返回一个包含服务器资源的Response对象给r完整参数:requests.get(url,params=None,**kwargs),实则由request方法封装</code></pre><p><strong>Response对象的五个属性:</strong></p><p><img src="http://img.blog.csdn.net/20171003091835125?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>爬取网页的通用代码框架</strong></p><pre><code>Requests库爬取网页会遇到异常:6种常见异常：</code></pre><p><img src="http://img.blog.csdn.net/20171003092400462?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>使用r.raise_for_status()方法构建通用代码框架:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python</div><div class="line"># coding=utf-8</div><div class="line">def getHTMLText(url)</div><div class="line">try:</div><div class="line">r = request.get(url,timeout = 30)</div><div class="line">r.raise_for_status()</div><div class="line">r.encoding = r.apparent_encoding</div><div class="line">return r.text</div><div class="line">except:</div><div class="line">return &quot;产生异常&quot;</div></pre></td></tr></table></figure><p><strong>HTTP协议对资源的操作:</strong></p><p><img src="http://img.blog.csdn.net/20171003094035525?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><p><strong>Requests库主要方法:requests.request(method,url,</strong>kwargs)**</p><pre><code>method(请求方式)包括:    GET/HEAD/POST/PUT/PATCH/delete/OPTIONS**kwargs(控制访问参数)包括:    params(添加键值到url后)/data(字典/字节序列等作为Request的内容)/json/headers(HTTP定制头)/cookies(Request中的cookie)/auth(元祖,支持HTTP认证)/files(传输文件)/timeout/proxies(设定访问代理服务器)/allow_redirects(重定向开关)/stream(获取内容立即下载开关)/verify(认证SSL证书开关)/cert(本地SSL证书路径)</code></pre><p><strong>Requests库爬取实例</strong></p><ul><li>京东商品页面的爬取</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">import requests</div><div class="line">url = &quot;http://item.jd.com/2967929.html&quot;</div><div class="line">try:</div><div class="line">    r=requests.get(url)</div><div class="line">    r.raise_for_status()</div><div class="line">    r.encoding=r.apparent_encoding</div><div class="line">    print(r.text[:1000])</div><div class="line">except:</div><div class="line">    print(&quot;爬取失败&quot;)</div></pre></td></tr></table></figure><ul><li>亚马逊商品页面的爬取<br>由于亚马逊有自身的头部审查,故我们模拟浏览器访问:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">import requests</div><div class="line">url = &quot;http://www.amazon.cn/gp/product/B01M8L5Z3Y&quot;</div><div class="line">try:</div><div class="line">    kv = &#123;&apos;user-agent&apos;:&apos;Mozilla/5.0&apos;&#125;</div><div class="line">    r= requests.get(url,headers = kv)</div><div class="line">    r.raise_for_status()</div><div class="line">    r.encoding=r.apparent_encoding</div><div class="line">    print(r.text[1000:2000])</div><div class="line">except:</div><div class="line">    print(&quot;爬取失败&quot;)</div></pre></td></tr></table></figure><ul><li>百度/360搜索关键词提交<br>首先我们需要知道搜索关键词的提交接口:<br>百度:<a href="http://www.baidu.com/s?wd=keyword" target="_blank" rel="external">http://www.baidu.com/s?wd=keyword</a><br>360:<a href="http://www.so.com/s?q=keyword" target="_blank" rel="external">http://www.so.com/s?q=keyword</a><br>接下来我们可以利用params参数将关键词加入,代码如下:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">import requests</div><div class="line">keyword = &quot;Python&quot;</div><div class="line">try:</div><div class="line">    kv = &#123;&apos;wd&apos;:keyword&#125;</div><div class="line">    r= requests.get(&quot;http://www.baidu.com/s&quot;,params = kv)</div><div class="line">    print(r.request.url)</div><div class="line">    r.raise_for_status()</div><div class="line">    print(len(r.text))</div><div class="line">except:</div><div class="line">    print(&quot;爬取失败&quot;)</div></pre></td></tr></table></figure><ul><li>网络图片的爬取和存储</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python</div><div class="line"># coding=utf-8</div><div class="line">import requests</div><div class="line">import os</div><div class="line">url = &quot;http://image.nationalgeographic.com.cn/2017/0311/20170311024522382.jpg&quot;</div><div class="line"></div><div class="line">root = &quot;/home/xiaorui/文档/Python/&quot;</div><div class="line">path = root +url.split(&apos;/&apos;)[-1]</div><div class="line">try:</div><div class="line">    if not os.path.exists(root):</div><div class="line">        os.mkdir(root)</div><div class="line">    if not os.path.exists(path):</div><div class="line">        r=requests.get(url)</div><div class="line">        with open(path,&apos;wb&apos;) as f:</div><div class="line">            f.write(r.content)</div><div class="line">            f.close()</div><div class="line">            print(&quot;文件保存成功&quot;)</div><div class="line">    else:</div><div class="line">        print(&quot;文件已存在&quot;)</div><div class="line">except:</div><div class="line">    print(&quot;爬取失败&quot;)</div></pre></td></tr></table></figure><ul><li>IP地址归属地的查询</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python</div><div class="line"># coding=utf-8</div><div class="line">import requests</div><div class="line">url = &quot;http://m.ip138.com/ip.asp?ip=&quot;</div><div class="line">try:</div><div class="line">    r=requests.get(url+&apos;202.204.80.112&apos;)</div><div class="line">    r.raise_for_status()</div><div class="line">    r.encoding=r.apparent_encoding</div><div class="line">    print(r.text[-500:])</div><div class="line">except:</div><div class="line">    print(&quot;爬取失败&quot;)</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Requests库的七个主要方法:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20171003091430199?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZ
      
    
    </summary>
    
      <category term="Python学习" scheme="http://wustxiao.cn/categories/Python%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Python" scheme="http://wustxiao.cn/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>markdown新手指南手册</title>
    <link href="http://wustxiao.cn/2017/10/09/markdown%E6%96%B0%E6%89%8B%E6%8C%87%E5%8D%97%E6%89%8B%E5%86%8C/"/>
    <id>http://wustxiao.cn/2017/10/09/markdown新手指南手册/</id>
    <published>2017-10-09T10:48:18.000Z</published>
    <updated>2017-10-09T11:15:54.030Z</updated>
    
    <content type="html"><![CDATA[<h3 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># 一级标题</div><div class="line">## 二级标题</div><div class="line">### 三级标题</div><div class="line">#### 四级标题</div><div class="line">##### 五级标题</div><div class="line">###### 六级标题</div></pre></td></tr></table></figure><h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><h4 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">- 文本1</div><div class="line">- 文本2</div><div class="line">- 文本3</div></pre></td></tr></table></figure><h4 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1. 文本1</div><div class="line">2. 文本2</div><div class="line">3. 文本3</div></pre></td></tr></table></figure><h3 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[显示文本](链接地址)</div></pre></td></tr></table></figure><h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">![](图片链接地址)</div></pre></td></tr></table></figure><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&gt; 需要引用的文本</div></pre></td></tr></table></figure><h3 id="粗体"><a href="#粗体" class="headerlink" title="粗体"></a>粗体</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">**文本**</div></pre></td></tr></table></figure><h3 id="斜体"><a href="#斜体" class="headerlink" title="斜体"></a>斜体</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">*文本*</div></pre></td></tr></table></figure><h3 id="代码引用"><a href="#代码引用" class="headerlink" title="代码引用"></a>代码引用</h3><p>用两个、、、包围需要引用的代码即可</p><h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">|Tables     |Are         |Cool   |</div><div class="line">|-----------------|:-----------|----|</div><div class="line">|col 3 is   |right-aligned | $1600  |</div><div class="line">|col 2 is   |centered    |  $12  |</div><div class="line">|zebra stripes  | are neat     | $1 |</div></pre></td></tr></table></figure><p><strong>显示效果：</strong></p><table><thead><tr><th>Tables</th><th style="text-align:left">Are</th><th>Cool</th></tr></thead><tbody><tr><td>col 3 is</td><td style="text-align:left">right-aligned</td><td>$1600</td></tr><tr><td>col 2 is</td><td style="text-align:left">centered</td><td>$12</td></tr><tr><td>zebra stripes</td><td style="text-align:left">are neat</td><td>$1</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;标题&quot;&gt;&lt;a href=&quot;#标题&quot; class=&quot;headerlink&quot; title=&quot;标题&quot;&gt;&lt;/a&gt;标题&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div c
      
    
    </summary>
    
      <category term="Linux学习" scheme="http://wustxiao.cn/categories/Linux%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="markdown" scheme="http://wustxiao.cn/tags/markdown/"/>
    
  </entry>
  
  <entry>
    <title>Hexo+Next主题 文章添加阅读次数，访问量等</title>
    <link href="http://wustxiao.cn/2017/10/06/Hexo-Next%E4%B8%BB%E9%A2%98-%E6%96%87%E7%AB%A0%E6%B7%BB%E5%8A%A0%E9%98%85%E8%AF%BB%E6%AC%A1%E6%95%B0%EF%BC%8C%E8%AE%BF%E9%97%AE%E9%87%8F%E7%AD%89/"/>
    <id>http://wustxiao.cn/2017/10/06/Hexo-Next主题-文章添加阅读次数，访问量等/</id>
    <published>2017-10-06T09:38:07.000Z</published>
    <updated>2017-10-06T09:40:09.672Z</updated>
    
    <content type="html"><![CDATA[<h3 id="本章所讲给文章设置阅读量，启用不蒜子统计，仅限于文章页面显示阅读书，在首页不显示。效果如下图所示："><a href="#本章所讲给文章设置阅读量，启用不蒜子统计，仅限于文章页面显示阅读书，在首页不显示。效果如下图所示：" class="headerlink" title="本章所讲给文章设置阅读量，启用不蒜子统计，仅限于文章页面显示阅读书，在首页不显示。效果如下图所示："></a>本章所讲给文章设置阅读量，启用不蒜子统计，仅限于文章页面显示阅读书，在首页不显示。效果如下图所示：</h3><p><img src="http://img.blog.csdn.net/20171006173642716?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><h3 id="打开-Hexo-目录下的-themes-next-config-yml-文件"><a href="#打开-Hexo-目录下的-themes-next-config-yml-文件" class="headerlink" title="打开 Hexo 目录下的 \themes\next\ _config.yml 文件"></a>打开 Hexo 目录下的 \themes\next\ _config.yml 文件</h3><p><img src="http://img.blog.csdn.net/20171006173704062?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;本章所讲给文章设置阅读量，启用不蒜子统计，仅限于文章页面显示阅读书，在首页不显示。效果如下图所示：&quot;&gt;&lt;a href=&quot;#本章所讲给文章设置阅读量，启用不蒜子统计，仅限于文章页面显示阅读书，在首页不显示。效果如下图所示：&quot; class=&quot;headerlink&quot; t
      
    
    </summary>
    
      <category term="Hexo学习" scheme="http://wustxiao.cn/categories/Hexo%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="hexo" scheme="http://wustxiao.cn/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>markdown 编辑器： remarkable 安装(ubuntu)</title>
    <link href="http://wustxiao.cn/2017/10/06/markdown-%E7%BC%96%E8%BE%91%E5%99%A8%EF%BC%9A-remarkable-%E5%AE%89%E8%A3%85-ubuntu/"/>
    <id>http://wustxiao.cn/2017/10/06/markdown-编辑器：-remarkable-安装-ubuntu/</id>
    <published>2017-10-06T08:49:00.000Z</published>
    <updated>2017-10-06T09:02:27.427Z</updated>
    
    <content type="html"><![CDATA[<ul><li>下载安装包</li><li><a href="http://remarkableapp.github.io/linux/download.html" target="_blank" rel="external">http://remarkableapp.github.io/linux/download.html</a></li></ul><ul><li>安装之：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dpkg -i remarkable_1.62_all.deb</div></pre></td></tr></table></figure><ul><li>补上依赖项：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install -f</div></pre></td></tr></table></figure><ul><li>运行：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">remarkable &amp;</div></pre></td></tr></table></figure><p><img src="http://img.blog.csdn.net/20171006170128354?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;下载安装包&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://remarkableapp.github.io/linux/download.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://remarkableapp.git
      
    
    </summary>
    
      <category term="安装软件" scheme="http://wustxiao.cn/categories/%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6/"/>
    
    
      <category term="软件" scheme="http://wustxiao.cn/tags/%E8%BD%AF%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客搭建（next主题系列详解）</title>
    <link href="http://wustxiao.cn/2017/10/06/Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%EF%BC%88next%E4%B8%BB%E9%A2%98%E7%B3%BB%E5%88%97%E8%AF%A6%E8%A7%A3%EF%BC%89/"/>
    <id>http://wustxiao.cn/2017/10/06/Hexo博客搭建（next主题系列详解）/</id>
    <published>2017-10-06T07:34:50.000Z</published>
    <updated>2017-10-06T07:36:02.190Z</updated>
    
    <content type="html"><![CDATA[<h3 id="hexo的next主题配置详解"><a href="#hexo的next主题配置详解" class="headerlink" title="hexo的next主题配置详解"></a><a href="http://michael728.github.io/2015/11/30/hexo-next-optimize/" target="_blank" rel="external">hexo的next主题配置详解</a></h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;hexo的next主题配置详解&quot;&gt;&lt;a href=&quot;#hexo的next主题配置详解&quot; class=&quot;headerlink&quot; title=&quot;hexo的next主题配置详解&quot;&gt;&lt;/a&gt;&lt;a href=&quot;http://michael728.github.io/2015
      
    
    </summary>
    
      <category term="Hexo学习" scheme="http://wustxiao.cn/categories/Hexo%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Hexo" scheme="http://wustxiao.cn/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://wustxiao.cn/2017/10/05/hello-world/"/>
    <id>http://wustxiao.cn/2017/10/05/hello-world/</id>
    <published>2017-10-05T15:22:50.669Z</published>
    <updated>2017-10-05T15:22:50.669Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p><p><div id="disqus_thread"></div></p><script>/***  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*//*var disqus_config = function () {this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variablethis.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable};*/(function() { // DON'T EDIT BELOW THIS LINEvar d = document, s = d.createElement('script');s.src = 'https://https-xrlrf-github-io.disqus.com/embed.js';s.setAttribute('data-timestamp', +new Date());(d.head || d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="external">comments powered by Disqus.</a></noscript><script id="dsq-count-scr" src="//https-xrlrf-github-io.disqus.com/count.js" async></script><!-- Global Site Tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-107582762-1"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-107582762-1');</script><!-- UY BEGIN --><p><div id="uyan_frame"></div></p><p><script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2145975"></script><br><!-- UY END --></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hexo博客使用系列（四）——文章里嵌入音乐播放器</title>
    <link href="http://wustxiao.cn/2017/10/05/Hexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8%E7%B3%BB%E5%88%97%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94%E6%96%87%E7%AB%A0%E9%87%8C%E5%B5%8C%E5%85%A5%E9%9F%B3%E4%B9%90%E6%92%AD%E6%94%BE%E5%99%A8/"/>
    <id>http://wustxiao.cn/2017/10/05/Hexo博客使用系列（四）——文章里嵌入音乐播放器/</id>
    <published>2017-10-05T15:04:39.000Z</published>
    <updated>2017-10-05T15:24:35.880Z</updated>
    
    <content type="html"><![CDATA[<p><strong>内嵌播放器</strong></p><p>打开网页版网易云<br>选择自己喜欢的音乐或歌单，点开歌曲名或者歌单名，点击生成外链播放器，赋值html代码，将html代码无需任何修改放入<br>markdown文章就可以了。可以取消自动播放。</p><p><img src="http://img.blog.csdn.net/20171005231522473?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveHI0Njk3ODY3MDY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="450" src="//music.163.com/outchain/player?type=0&id=786956365&auto=1&height=430"></iframe>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;内嵌播放器&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;打开网页版网易云&lt;br&gt;选择自己喜欢的音乐或歌单，点开歌曲名或者歌单名，点击生成外链播放器，赋值html代码，将html代码无需任何修改放入&lt;br&gt;markdown文章就可以了。可以取消自动播放。&lt;/p&gt;
&lt;p&gt;&lt;
      
    
    </summary>
    
      <category term="hexo学习" scheme="http://wustxiao.cn/categories/hexo%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="hexo" scheme="http://wustxiao.cn/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>Python/Django生成二维码</title>
    <link href="http://wustxiao.cn/2017/10/05/Python%E7%94%9F%E6%88%90%E4%BA%8C%E7%BB%B4%E7%A0%81/"/>
    <id>http://wustxiao.cn/2017/10/05/Python生成二维码/</id>
    <published>2017-10-05T11:00:00.000Z</published>
    <updated>2017-10-05T15:24:09.545Z</updated>
    
    <content type="html"><![CDATA[<h2 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h2><h3 id="1-1-用Python来生成二维码很简单，可以看-qrcode-这个包："><a href="#1-1-用Python来生成二维码很简单，可以看-qrcode-这个包：" class="headerlink" title="1.1 用Python来生成二维码很简单，可以看 qrcode 这个包："></a>1.1 用Python来生成二维码很简单，可以看 qrcode 这个包：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install qrcode</div></pre></td></tr></table></figure><p>qrcode 依赖 Image 这个包：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install Image</div></pre></td></tr></table></figure><h3 id="1-2-安装后就可以使用了，这个程序带了一个-qr-命令："><a href="#1-2-安装后就可以使用了，这个程序带了一个-qr-命令：" class="headerlink" title="1.2 安装后就可以使用了，这个程序带了一个 qr 命令："></a>1.2 安装后就可以使用了，这个程序带了一个 qr 命令：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">qr &apos;http://www.ziqiangxuetang.com&apos; &gt; test.png</div></pre></td></tr></table></figure><h3 id="1-3-下面我们看一下如何在-代码-中使用"><a href="#1-3-下面我们看一下如何在-代码-中使用" class="headerlink" title="1.3 下面我们看一下如何在 代码 中使用"></a>1.3 下面我们看一下如何在 代码 中使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">import qrcode</div><div class="line"></div><div class="line">img = qrcode.make(&apos;http://www.tuweizhong.com&apos;)</div><div class="line"># img &lt;qrcode.image.pil.PilImage object at 0x1044ed9d0&gt;</div><div class="line"></div><div class="line">with open(&apos;test.png&apos;, &apos;wb&apos;) as f:</div><div class="line">    img.save(f)</div></pre></td></tr></table></figure><p>安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pip install git+git://github.com/ojii/pymaging.git#egg=pymaging</div><div class="line">pip install git+git://github.com/ojii/pymaging-png.git#egg=pymaging-png</div></pre></td></tr></table></figure><p>使用方法大致相同，命令行上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">qr --factory=pymaging &quot;Some text&quot; &gt; test.png</div></pre></td></tr></table></figure><p>Python中调用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">import qrcode</div><div class="line">from qrcode.image.pure import PymagingImage</div><div class="line">img = qrcode.make(&apos;Some data here&apos;, image_factory=PymagingImage)</div></pre></td></tr></table></figure><p><div id="disqus_thread"></div></p><script>/***  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*//*var disqus_config = function () {this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variablethis.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable};*/(function() { // DON'T EDIT BELOW THIS LINEvar d = document, s = d.createElement('script');s.src = 'https://https-xrlrf-github-io.disqus.com/embed.js';s.setAttribute('data-timestamp', +new Date());(d.head || d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="external">comments powered by Disqus.</a></noscript><script id="dsq-count-scr" src="//https-xrlrf-github-io.disqus.com/count.js" async></script><!-- Global Site Tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-107582762-1"></script><script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'UA-107582762-1');</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;开始安装&quot;&gt;&lt;a href=&quot;#开始安装&quot; class=&quot;headerlink&quot; title=&quot;开始安装&quot;&gt;&lt;/a&gt;开始安装&lt;/h2&gt;&lt;h3 id=&quot;1-1-用Python来生成二维码很简单，可以看-qrcode-这个包：&quot;&gt;&lt;a href=&quot;#1-1-用Pyth
      
    
    </summary>
    
      <category term="Python学习" scheme="http://wustxiao.cn/categories/Python%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Python" scheme="http://wustxiao.cn/tags/Python/"/>
    
  </entry>
  
</feed>
